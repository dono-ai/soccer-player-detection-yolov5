{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1256c3fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "\n",
        "# Load model\n",
        "output_path = \"../output\"\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='../models/best.pt')\n",
        "\n",
        "model.conf = 0.1\n",
        "model.iou = 0.3\n",
        "model.agnostic = True  \n",
        "\n",
        "file_path = \"../test_data/video1.mp4\"\n",
        "\n",
        "results = model(file_path)\n",
        "results.show()\n",
        "# cap = cv2.VideoCapture(file_path)\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model.to(device)\n",
        "# writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"MJPG\"), int(cap.get(cv2.CAP_PROP_FPS)), (width, height))\n",
        "\n",
        "# while cap.isOpened():\n",
        "#     flag, frame = cap.read()\n",
        "#     if not flag:\n",
        "#         print(f\"Finished or error reading a video\")\n",
        "#         break\n",
        "#     predictions = model(frame, size=width)\n",
        "#     # for box, label, score in zip(predictions[\"boxes\"], predictions[\"labels\"], predictions[\"scores\"]):\n",
        "#     #     if score > args.conf_threshold:\n",
        "#     #         xmin, ymin, xmax, ymax = box.int().tolist()\n",
        "#     #         cv2.rectangle(ori_frame, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
        "#     #         cv2.putText(ori_frame, classes[label], (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "#     #                     2, (0, 255, 0), 4, cv2.LINE_AA)\n",
        "#     # writer.write(ori_frame)\n",
        "#     print(\"test: \", predictions)\n",
        "#     break\n",
        "# cap.release()\n",
        "# # # # Print and show\n",
        "# # results.print()\n",
        "# # results.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478f41a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/dono/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2025-5-17 Python-3.10.16 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4070, 11884MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to trained model weights\n",
        "model_path = '../models/best.pt'  # update this if needed\n",
        "\n",
        "# Load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
        "\n",
        "# Video input and output\n",
        "video_path = '../test_data/video1.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get original video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width, height = 3840, 1200\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output_inference.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(frame, size=3840)  # match your training img size\n",
        "\n",
        "    # Render detections on frame\n",
        "    annotated_frame = results.render()[0]\n",
        "\n",
        "    # Write frame to output\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1a4aee",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/dono/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2025-5-17 Python-3.10.16 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4070, 11884MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Path to trained model weights\n",
        "model_path = '../models/best.pt'  # update this if needed\n",
        "\n",
        "# Load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
        "\n",
        "# Video input and output\n",
        "video_path = '../test_data/video1.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "output_name = \"test.mp4\"\n",
        "output_path = os.path.join(\"../output\", output_name)\n",
        "\n",
        "# Get original video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width, height = 3840, 1200\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # frame_resized = cv2.resize(frame, (1920, 600))\n",
        "    with torch.no_grad():\n",
        "        results = model(frame, size=3840)\n",
        "        annotated_frame = results.render()[0]\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "        torch.cuda.empty_cache() \n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()     "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "football",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
